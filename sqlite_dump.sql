PRAGMA foreign_keys=OFF;
BEGIN TRANSACTION;
CREATE TABLE user (
	id INTEGER NOT NULL, 
	username VARCHAR(20) NOT NULL, 
	password VARCHAR(80) NOT NULL, 
	PRIMARY KEY (id), 
	UNIQUE (username)
);
INSERT INTO user VALUES(1,'nididier','mukiza123');
INSERT INTO user VALUES(2,'amani','leo123');
CREATE TABLE post (
	id INTEGER NOT NULL, 
	title VARCHAR(255) NOT NULL, 
	content TEXT NOT NULL, 
	date_posted DATETIME NOT NULL, 
	author_id INTEGER NOT NULL, 
	PRIMARY KEY (id), 
	FOREIGN KEY(author_id) REFERENCES user (id)
);
INSERT INTO post VALUES(1,'What is Artificial Intelligence?',replace(replace('Artificial intelligence (AI) can be understood as the ability of computers to do things that we typically think only humans can do. Imagine teaching a computer to understand languages, recognize speech, or even figure out what''s in a picture. That''s what AI does.\r\nWhen we talk about AI, we often think about teaching computers to learn from a lot of examples. For example, if we want a computer to recognize spam emails, we give it lots of examples of spam and non-spam emails so it can learn the difference.\r\n\r\nNow, computers aren''t exactly "smart" like humans. They don''t have thoughts or feelings. Instead, they follow instructions fast. But with AI, we can make computers seem smart by teaching them to learn from lots of examples. Can computers really think? Computers, as we know them today, don''t possess consciousness or subjective experience. They operate based on predefined algorithms and instructions provided by programmers. They don''t have emotions, desires, or personal experiences like humans do. However, computers are becoming increasingly adept at performing tasks that were once thought to require human intelligence. Through techniques like machine learning and artificial neural networks, computers can process large amounts of data, recognize patterns, make predictions, and even learn from experience. AI holds the potential to augment human capabilities rather than replace them. By automating repetitive tasks and providing intelligent insights, AI empowers individuals and organizations to focus on higher-value work, creativity, and innovation. However, the proliferation of AI raises critical ethical and societal questions that demand careful consideration. Issues such as algorithmic bias and  data privacy necessitate proactive measures to ensure inclusivity, representability, equity and transparency during research, design, training and testing phases of AI systems.\r\n','\r',char(13)),'\n',char(10)),'2024-03-27 04:58:53.981165',1);
INSERT INTO post VALUES(2,'Understanding Strong AI and Weak AI','Artificial intelligence (AI) is a constantly evolving field with the potential to revolutionize many aspects of our lives. Larry Page, the co-founder of Google, envisioned a future where AI could understand our desires and provide solutions. While we are not there yet, significant progress has been made. Weak AI, also known as narrow AI, is what we encounter most often today. These are AI systems that are designed to perform specific tasks very well. For example, virtual assistants like Siri, Cortana, and Alexa can answer questions, schedule appointments, and control smart home devices. Weak AI systems are not sentient or conscious, and they cannot think for themselves. They are simply very good at following the instructions they have been programmed with. Strong AI, also known as artificial general intelligence (AGI), is the kind of AI that science fiction movies are made of. Strong AI would be able to understand and reason like a human being. It would be able to learn and adapt to new situations, and it would be able to solve problems that it has never encountered before. One way to think about the difference between strong AI and weak AI is the Turing test. The Turing test is a thought experiment proposed by Alan Turing in which a human evaluator converses with a human and a machine in a written chat. If the evaluator cannot tell the difference between the human and the machine, then the machine is said to have passed the Turing test. We are still a long way from achieving strong AI, but there is no doubt that AI is becoming increasingly sophisticated. Weak AI systems are already having a major impact on our lives, and they are only going to become more common in the future. As AI continues to develop, it is important to have a conversation about the ethical implications of this technology.','2024-03-27 05:01:05.638515',1);
INSERT INTO post VALUES(3,'Takeaway from the latest threat notifications by Apple',replace(replace('A couple days ago, Apple sent out threat notifications to the users intending to inform them about mercenary spyware attacks. While the company did not attribute the attacks to any “any specific attackers”, in their official statement to the users, Apple made a subtle reference to Pegasus malware made by a company called NSO Group. Back in 2019 WhatsApp filed a lawsuit against NSO Group claiming that the latter exploited an audio-calling vulnerability on their application. \r\nWhatsApp, which is owned by a technology conglomerate Meta, in their official statement admitted that “A missing bounds check within the audio decoding pipeline for WhatsApp calls in WhatsApp for Android prior to v2.21.3, WhatsApp Business for Android prior to v2.21.3, WhatsApp for iOS prior to v2.21.32, and WhatsApp Business for iOS prior to v2.21.32 could have allowed an out-of-bounds write.”\r\nOut-of-bounds reads or writes can be leveraged by attackers to manipulate program behavior, execute arbitrary code, or gain unauthorized access to sensitive information. Imagine you have secrets in your notebook, and you have used in for so many years that it’s now full. However, you still need to add more secrets. Now, instead of purchasing a new notebook, you decide to write your additional secrets to the notebook cover. Because you have put those secrets outside the boundaries of your notebook, malicious people can very easily access those. Out of bounds read/write works in that sense.\r\nApple recommends affected users to reach out to Access Now. The regular users, who have valid reasons to suspect a possible attack against them, are recommended to run their devices in “Lockdown mode”. Apple’s support page provides more clarity on how to run your devices in that mode and the trade offs that could be associated to that.\r\nIn the summer of 2023, we extensively covered this Pegasus malware and formulated a well elaborated document with recommendations for users potentially affected, regardless of their operating systems. If you''re keen on delving deeper into understanding how this spyware infiltrates devices, the victims, its surveillance functionalities, and the methods of attaining administrative privileges to exploit the systems , feel free to get in touch with us.\r\n','\r',char(13)),'\n',char(10)),'2024-04-15 01:21:55.862987',1);
INSERT INTO post VALUES(4,'Unveiling Ethical Concerns in AI: Bias and Privacy at the Forefront',replace(replace('In today''s tech-driven world, AI offers incredible possibilities across various fields. But as we celebrate its potential, it''s vital to talk about the ethical dilemmas it brings. Two big issues stand out: bias and privacy.\r\nFirst, let''s talk about bias. AI systems aren''t as impartial as they might seem. They learn from the data they''re given, and if that data is biased, the AI will be too. For example, facial recognition software has been found to be less accurate for people depending on their geographical location on the globe. Plus, the data used in AI research often leaves out important groups, like certain demographics in healthcare studies, leading to incomplete or misleading conclusions. If you have been using AI tools for speech recognition, text translation or image recognition, I am sure you have noticed at least one hilarious instance of AI confusing one person to another. I have had a chance to evaluate various language models from corporates and open source, what they have in common is that they are more knowledgeable about some parts of the world that others, and training data can be one of the key contributors to this issue.\r\nNext up, privacy. Some AI models learn from our behavior without us knowing. Think of smart home devices that might listen in on our conversations without permission. It''s like having someone constantly watching and learning from us without our say-so. Or imagine the possibilities of language models using the data you provided while prompting to continuously improving themselves (reinforcement learning)\r\nWe need to tackle these challenges to ensure AI benefits everyone and respects our rights. Companies should be more transparent and open source for users to have full clarity of how there is being used. In short, AI has amazing potential, but we can''t ignore its ethical problems. By being transparent, accountable, and inclusive in how we design, develop and test AI systems, we can create a future where it enhances our lives without compromising our values.\r\nExpanding the scope of AI research to include data from diverse regions across the globe is crucial for building more equitable and representative AI systems. Currently, much of the data used in AI development comes from specific regions or demographics, which can perpetuate biases and inaccuracies.\r\nBy gathering data from a wider range of sources, we can better capture the richness and diversity of human experiences and behaviors. This not only helps to mitigate biases but also ensures that AI systems are more inclusive, smarter across different cultural contexts.\r\n\r\n','\r',char(13)),'\n',char(10)),'2024-05-01 00:43:46.544371',1);
COMMIT;
